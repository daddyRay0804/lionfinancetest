import { NextRequest, NextResponse } from "next/server";
import { getSystemPrompt } from "@/data/aiPrompt";
import { API_NOT_CONFIGURED } from "@/data/aiPrompt";
import type { Lang } from "@/lib/i18n";

/* ---- OpenRouter é…ç½® ---- */
const API_URL = "https://openrouter.ai/api/v1/chat/completions";
// Prefer a stable chat model for customer-facing Q&A (free models tend to be flaky)
const MODEL = "deepseek/deepseek-chat";

type ChatMessage = { role: "user" | "assistant"; content: string };

function isValidLang(lang: string): lang is Lang {
  return lang === "en" || lang === "zh" || lang === "kr";
}

export async function POST(request: NextRequest) {
  try {
    const reqBody = await request.json();
    const { messages = [], lang = "en" } = reqBody as {
      messages?: ChatMessage[];
      lang?: string;
    };

    const language = isValidLang(lang) ? lang : "en";
    /* Vercel ç¯å¢ƒå˜é‡å: aibot */
    const apiKey = process.env.aibot?.trim();

    if (!apiKey) {
      return NextResponse.json(
        { content: API_NOT_CONFIGURED[language], stream: false },
        { status: 200 }
      );
    }

    const systemPrompt = getSystemPrompt(language);

    /* DeepSeek R1 ä½¿ç”¨æ ‡å‡† system è§’è‰² */
    const apiMessages: { role: string; content: string }[] = [
      { role: "system", content: systemPrompt },
      ...messages.map((m) => ({
        role: m.role,
        content: m.content,
      })),
    ];

    console.log("[api/chat] Calling OpenRouter:", MODEL, "messages:", apiMessages.length);

    /* ---------- ä½¿ç”¨ non-streaming è¯·æ±‚ï¼ˆå…è´¹æ¨¡å‹æ›´ç¨³å®šï¼‰ ---------- */
    const res = await fetch(API_URL, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${apiKey}`,
        "HTTP-Referer": "https://lionfinance.co.nz",
        "X-Title": "Lion Finance AI Assistant",
      },
      body: JSON.stringify({
        model: MODEL,
        messages: apiMessages,
        // Give the model enough room to finish an answer; low temperature reduces hallucination.
        max_tokens: 800,
        temperature: 0.3,
        include_reasoning: false,
      }),
    });

    if (!res.ok) {
      const errText = await res.text();
      console.error("[api/chat] OpenRouter error:", res.status, errText.slice(0, 800));

      /* 400/422ï¼šå°è¯•æç®€è¯·æ±‚ï¼ˆå»æ‰ temperature/max_tokensï¼‰ */
      if (res.status === 400 || res.status === 422) {
        console.log("[api/chat] Retrying with minimal params...");
        const retry = await fetch(API_URL, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            Authorization: `Bearer ${apiKey}`,
            "HTTP-Referer": "https://lionfinance.co.nz",
            "X-Title": "Lion Finance AI Assistant",
          },
          body: JSON.stringify({
            model: MODEL,
            messages: apiMessages,
            include_reasoning: false,
          }),
        });

        if (retry.ok) {
          const json = (await retry.json()) as {
            choices?: Array<{ message?: { content?: string } }>;
          };
          const content = json.choices?.[0]?.message?.content ?? "";
          return NextResponse.json({ content, stream: false }, { status: 200 });
        }

        const retryErr = await retry.text();
        console.error("[api/chat] Retry also failed:", retry.status, retryErr.slice(0, 800));
        return NextResponse.json(
          { content: `âš ï¸ AI æš‚æ—¶æ— æ³•è¿æ¥ (${retry.status})ã€‚è¯·ç¨åå†è¯•æˆ–ç›´æ¥è”ç³»æˆ‘ä»¬çš„å›¢é˜Ÿï¼\n\nğŸ“§ gary@lionfinance.co.nz / 022 161 9172\nğŸ“§ allan@lionfinance.co.nz / 021 153 1918` },
          { status: 200 }
        );
      }

      /* é 400/422 çš„å…¶ä»–é”™è¯¯ */
      const detail = res.status === 401
        ? "API key æ— æ•ˆï¼Œè¯·æ£€æŸ¥ Vercel ç¯å¢ƒå˜é‡ aibot çš„å€¼"
        : res.status === 429
          ? "è¯·æ±‚å¤ªé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•"
          : errText.slice(0, 200);
      return NextResponse.json(
        { content: `âš ï¸ è¿æ¥å‡ºäº†ç‚¹é—®é¢˜ (${res.status})ï¼š${detail}` },
        { status: 200 }
      );
    }

    /* ---------- æˆåŠŸï¼šè§£æå“åº” ---------- */
    const json = (await res.json()) as {
      choices?: Array<{ message?: { content?: string } }>;
      error?: { message?: string };
    };

    if (json.error) {
      console.error("[api/chat] OpenRouter response error:", json.error);
      return NextResponse.json(
        { content: `âš ï¸ ${json.error.message ?? "Unknown error"}` },
        { status: 200 }
      );
    }

    const content = json.choices?.[0]?.message?.content ?? "";
    return NextResponse.json({ content, stream: false }, { status: 200 });
  } catch (e) {
    console.error("[api/chat] Server error:", e);
    return NextResponse.json(
      { content: "âš ï¸ æœåŠ¡å™¨å‡ºäº†ç‚¹é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ï¼" },
      { status: 200 }
    );
  }
}
